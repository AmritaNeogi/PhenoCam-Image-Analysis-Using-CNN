# -*- coding: utf-8 -*-
"""Phenophase_GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ilWzMqQ0bysLBQ7DqEEmyPA0UB-txR7M
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
import pandas as pd
import os
from sklearn.preprocessing import MinMaxScaler
from sklearn.utils import shuffle
import numpy as np
from skimage import io, transform
from sklearn.metrics import mean_squared_error

# Define paths
image_folder = "/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/"
label_file = "/content/drive/MyDrive/Capstone/data_out/labeled_data.csv"

# Function to recursively get all image paths in a directory
def get_all_image_paths(directory):
    image_paths = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    return image_paths

# Get all image paths in the base folder
all_image_paths = get_all_image_paths(image_folder)
# Sort the image paths alphabetically
sorted_image_paths = sorted(all_image_paths)

# Display the first image found
if all_image_paths:
    image_path = sorted_image_paths[0]
    image = plt.imread(image_path)

    plt.imshow(image)
    plt.title(f"Example Image: {image_path}")
    plt.show()
else:
    print("No images found in the specified directory.")

from skimage import io, transform

def preprocess_image(file_path):
    img = io.imread(file_path)

    # Resize the image without rescaling pixel values
    img = transform.resize(img, (224, 224), preserve_range=True)

    # Ensure the image has 3 channels (RGB)
    if img.shape[-1] == 1:
        img = np.stack([img.squeeze()] * 3, axis=-1)

    # Normalize pixel values to the range [0, 1]
    img = img.astype(np.float32) / 255.0

    return img

# Load and preprocess images
images = []

# Load and process labels
labels = pd.read_csv(label_file)
processed_labels = []

for root, dirs, files in os.walk(image_folder):
    for file in files:
        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(root, file)
            img = preprocess_image(image_path)
            images.append(img)

            # Extract corresponding label based on the filename
            filename = os.path.relpath(image_path, image_folder)
            label_row = labels[labels['Filename'] == filename]
            if not label_row.empty:
                processed_labels.append(label_row['Label'].values[0])
            else:
                processed_labels.append(None)  # Handle cases where the label is not found

# Convert the lists to NumPy arrays
images = np.array(images)
processed_labels = np.array(processed_labels)

# Display the shapes of the processed images and labels arrays
print("Shape of the processed images array:", images.shape)
print("Shape of the processed labels array:", processed_labels.shape)

import numpy as np
import matplotlib.pyplot as plt

im = images[0]
# Display the image using Matplotlib
plt.imshow(im)
plt.axis('off') # Optional: turn off axis labels
plt.show()

# Convert images and labels to NumPy arrays
images = np.array(images)
labels = labels[['GCC']].to_numpy()

# Normalize GCC values
scaler = MinMaxScaler()
labels = scaler.fit_transform(labels)

# Shuffle the data
images, labels = shuffle(images, labels, random_state=42)

labels[0]

first_image = images[0]

import numpy as np
import matplotlib.pyplot as plt

# Display the image using Matplotlib
plt.imshow(first_image)
plt.axis('off')  # Optional: turn off axis labels
plt.show()

# Define the GAN model
latent_dim = 100  # Adjust the size as needed

# Generator model
generator = models.Sequential([
    layers.Input(shape=(latent_dim,)),
    layers.Dense(7 * 7 * 256),
    layers.Reshape((7, 7, 256)),
    layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2DTranspose(3, (4, 4), strides=(4, 4), padding='same', activation='sigmoid'),  # Adjust strides here
    layers.Reshape((224, 224, 3))  # Reshape to the desired output shape
])

# # Discriminator model
discriminator = models.Sequential([
    layers.Input(shape=(224, 224, 3)),  # Adjust input shape
    layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Flatten(),
    layers.Dense(1, activation='sigmoid')
])

# Compile the discriminator
discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])

# Compile the generator
generator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')

"""##Do not Run"""

# CHECKING- No need to run

generator = models.Sequential([
    layers.Input(shape=(latent_dim,)),
    layers.Dense(7 * 7 * 256),
    layers.Reshape((7, 7, 256)),
    layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2DTranspose(3, (4, 4), strides=(4, 4), padding='same', activation='sigmoid'),  # Adjust strides here
    layers.Reshape((224, 224, 3))  # Reshape to the desired output shape
])
# Verify the output shape of the generator
dummy_input = tf.random.normal(shape=(1, latent_dim))
generator_output = generator(dummy_input)
print(generator_output.shape)  # Check if the output shape matches (224, 224, 3)

# CHECKING- No need to run

from tensorflow.keras import layers, models

discriminator = models.Sequential([
    layers.Input(shape=(224, 224, 3)),  # Adjust input shape
    layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', activation='relu'),
    layers.Flatten(),
    layers.Dense(1, activation='sigmoid')
])

# Print the model summary to verify the changes
discriminator.summary()

"""##GAN model"""

# Combined GAN model
discriminator.trainable = False
gan_input = layers.Input(shape=(latent_dim,))
generated_image = generator(gan_input)
gan_output = discriminator(generated_image)
gan_model = models.Model(gan_input, gan_output)
gan_model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')

# Training the GAN
epochs = 1000  # Adjust as needed
batch_size = 64  # Adjust as needed

# Disable eager execution
tf.config.run_functions_eagerly(False)

for epoch in range(epochs):
    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))
    generated_images = generator.predict(noise)

    idx = np.random.randint(0, images.shape[0], batch_size)
    real_images = images[idx]
    real_labels = labels[idx]

    # Train discriminator
    real_labels = np.ones((batch_size, 1))  # Updated line
    d_loss_real = discriminator.train_on_batch(real_images, real_labels)
    d_loss_fake = discriminator.train_on_batch(generated_images, np.zeros((batch_size, 1)))
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # Train generator
    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))
    valid_labels = np.ones((batch_size, 1))
    g_loss = gan_model.train_on_batch(noise, valid_labels)

    # Print progress
    if epoch % 100 == 0:
        print(f"Epoch {epoch}, D Loss: {d_loss}, G Loss: {g_loss}")

import numpy as np
from skimage import img_as_ubyte, io
import matplotlib.pyplot as plt

latent_dim = 100  # Adjust as needed

# Function to generate and return images along with indices
def generate_images_with_indices(num_images):
    noise = np.random.normal(0, 1, size=(num_images, latent_dim))
    generated_images = generator.predict(noise)
    return generated_images, range(len(generated_images))

# Generate 1 new image
new_images, generated_indices = generate_images_with_indices(2) # change the number of images accordingly

# Save the generated images and display them
for generated_image, generated_index in zip(new_images, generated_indices):
    # Convert the image to uint8 format (0-255)
    generated_image_uint8 = img_as_ubyte(generated_image)
    # Save the generated image
    io.imsave(f"/content/drive/MyDrive/Capstone/data_out/generated_image_{generated_index}.jpg", generated_image_uint8)
    # Display the generated image
    plt.imshow(generated_image_uint8)
    plt.title(f"Generated Image (Index {generated_index})")
    plt.show()
# Display the generated indices
print(f"Generated Indices: {list(generated_indices)}")

import matplotlib.pyplot as plt

# Function to display images with their GCC values
def display_images(actual_image, generated_image, actual_gcc, generated_gcc, index):
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    # Display actual image
    axes[0].imshow(actual_image)
    axes[0].set_title(f"Actual Image (Index {index})\nGCC: {actual_gcc[0]:.2f}")

    # Display generated image
    axes[1].imshow(generated_image)
    axes[1].set_title(f"Generated Image (Index {index})\nGCC: {generated_gcc[0]:.2f}")

    plt.show()

# Example: Display actual and generated images
index_to_display = 1  # Replace with the index of the image you want to display
actual_image = images[index_to_display]
actual_gcc = labels[index_to_display]

# Assuming `new_images` is a list of generated images
generated_image = new_images[index_to_display]
generated_gcc = scaler.inverse_transform(generated_image.reshape(1, -1))[0]

display_images(actual_image, generated_image, actual_gcc, generated_gcc, index_to_display)

"""## Exp: Next Day Image"""

import numpy as np
from skimage import img_as_ubyte, io
import matplotlib.pyplot as plt

latent_dim = 100  # Adjust as needed

# Function to generate and return images along with indices
def generate_next_day_image(input_image, num_images=1):
    # Generate noise for the next day image
    noise = np.random.normal(0, 1, size=(num_images, latent_dim))

    # Generate the next day's image
    generated_images = generator.predict([noise])

    return generated_images[0]

# Example: Load an input image for one day
input_image_path = "/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/2017/01/NEON.D01.HARV.DP1.00033_2017_01_02_120006.jpg"
#input_image = io.imread(input_image_path)

input_image = preprocess_image(input_image_path) # Generate the next day's image
next_day_image = generate_next_day_image(input_image, num_images=1)

# Convert the image to uint8 format (0-255)
next_day_image_uint8 = img_as_ubyte(next_day_image)
# Save the generated image
io.imsave("/content/drive/MyDrive/Capstone/data_out/next_day_generated_image.jpg", next_day_image_uint8)

# Display the generated image
plt.imshow(next_day_image_uint8)
plt.title("Next Day Generated Image")
plt.show()

import numpy as np
from skimage import img_as_ubyte, io
import matplotlib.pyplot as plt
import os

latent_dim = 100  # Adjust as needed

# Function to generate and return images along with indices
def generate_next_day_image(input_image, num_images=1):
    # Generate noise for the next day image
    noise = np.random.normal(0, 1, size=(num_images, latent_dim))
    # Generate the next day's image
    generated_images = generator.predict([noise])
    return generated_images[0]

# Function to recursively get all image paths in a directory
def get_all_image_paths(directory):
    image_paths = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    return image_paths

# Get all image paths in the base folder
image_folder =  "/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/"
all_image_paths = get_all_image_paths(image_folder)
# Sort the image paths alphabetically
sorted_image_paths = sorted(all_image_paths)

# Choose an index for the input image
input_image_index = 0  # Change this to the desired index

# Load the input image
input_image_path = sorted_image_paths[input_image_index]
input_image = io.imread(input_image_path)

# Generate the next day's image
next_day_image = generate_next_day_image(input_image, num_images=1)

# Convert the image to uint8 format (0-255)
next_day_image_uint8 = img_as_ubyte(next_day_image)

# Save the generated image
output_image_path = "/content/drive/MyDrive/Capstone/data_out/GAN_Images/image_1.jpg"  # Change this to the desired path
io.imsave(output_image_path, next_day_image_uint8)

# Display the input image
plt.subplot(1, 2, 1)
plt.imshow(input_image)
plt.title("Input Image")

# Display the generated image
plt.subplot(1, 2, 2)
plt.imshow(next_day_image_uint8)
plt.title("Next Day Generated Image")

plt.show()

import numpy as np
from skimage import img_as_ubyte, io
import matplotlib.pyplot as plt
import os

latent_dim = 100  # Adjust as needed

# Function to generate and return images along with indices
def generate_next_day_image(input_image, num_images=1):
    # Generate noise for the next day image
    noise = np.random.normal(0, 1, size=(num_images, latent_dim))
    # Generate the next day's image
    generated_images = generator.predict([noise])
    return generated_images[0]

# Function to recursively get all image paths in a directory
def get_all_image_paths(directory):
    image_paths = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    return image_paths

# Get all image paths in the base folder
image_folder = "/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/"
all_image_paths = get_all_image_paths(image_folder)
# Sort the image paths alphabetically
sorted_image_paths = sorted(all_image_paths)

# Choose an index for the input image
input_image_index = 0  # Change this to the desired index

# Load the input image
input_image_path = sorted_image_paths[input_image_index]
input_image = io.imread(input_image_path)

# Load the actual next day image
next_day_image_index = input_image_index + 1
next_day_image_path = sorted_image_paths[next_day_image_index]
actual_next_day_image = io.imread(next_day_image_path)

# Generate the next day's image
generated_next_day_image = generate_next_day_image(input_image, num_images=1)

# Convert the generated image to uint8 format (0-255)
generated_next_day_image_uint8 = img_as_ubyte(generated_next_day_image)
# Save the generated image
output_image_path = "/content/drive/MyDrive/Capstone/data_out/GAN_Images/GAN_next_day_image.jpg"  # Change this to the desired path
io.imsave(output_image_path, generated_next_day_image_uint8)

def display_actual_and_generated_images(actual_image, generated_image):
    # Convert the generated image to uint8 format (0-255)
    generated_image_uint8 = img_as_ubyte(generated_image)

    # Get the dimensions of the actual image
    actual_height, actual_width, _ = actual_image.shape

    # Get the aspect ratio of the actual image
    actual_aspect_ratio = actual_width / actual_height

    # Create a figure with two subplots
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    # Display actual next day image with explicit extent
    axes[0].imshow(actual_image, extent=[0, actual_width, actual_height, 0], aspect='auto')
    axes[0].set_title("Actual Next Day Image")

    # Display generated next day image with explicit extent
    axes[1].imshow(generated_image_uint8, extent=[0, actual_width, actual_height, 0], aspect='auto')
    axes[1].set_title("Generated Next Day Image")


    # Show the figure
    plt.show()

display_actual_and_generated_images(actual_next_day_image, generated_next_day_image)