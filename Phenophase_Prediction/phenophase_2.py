# -*- coding: utf-8 -*-
"""Phenophase_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sQ07H8OKptfWT-1Dw9ifwFehyiq0VEDR
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install torchvision
!pip install tensorflow
!pip install keras

import csv
import cv2
import os
import numpy as np
import pandas as pd
from PIL import Image
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from datetime import datetime, timedelta

"""##Get all the files in the directory"""

# SITE_NAME = "NEON.D01.HARV.DP1.00033"
# YEAR  = 2017

def list_files(filepath, filetype):
    paths = []
    for root, dirs, files in os.walk(filepath):
        for file in files:
            if file.lower().endswith(filetype.lower()):
                paths.append(os.path.join(root, file))
    return paths

#img_files = list_files(f'/content/drive/MyDrive/Capstone/data_raw/phenocamdata/{SITE_NAME}/{YEAR}', ".jpg")
img_files = list_files(f'/content/drive/MyDrive/Capstone/data_raw/phenocamdata/', ".jpg")
img_files.sort() # due to the way the file name is set up, sorting will sort it by date as well
img_files

#type(img_files)

#img_files[:5]
len(img_files)
#my_list[-5:]

"""##Data Preprocessing"""

# Function to load and preprocess images
def load_and_preprocess_images(image_directory):
    images = []

    # # Iterate over subdirectories (assuming they represent months)
    # for month_folder in os.listdir(image_directory):
    #     month_path = os.path.join(image_directory, month_folder)

    #     # Check if it's a directory
    #     if os.path.isdir(month_path):
    #         print(f"Loading images from {month_folder}...")

    for filename in os.listdir(image_directory):
      if filename.endswith(".jpg") or filename.endswith(".png"):
        img_path = os.path.join(image_directory, filename)
        img = cv2.imread(img_path)

        new_height = 224
        aspect_ratio = img.shape[1] / img.shape[0]
        new_width = int(new_height * aspect_ratio)
        img_resized = cv2.resize(img, (new_width, new_height))
        img_normalized = img_resized / 255.0

        images.append(img_normalized)

        #print(f"Number of images loaded from {month_folder}: {len(images)}")

    return np.array(images)

   # Load and preprocess the images
processed_images = load_and_preprocess_images(f'/content/drive/MyDrive/Capstone/data_raw/phenocamdata/{SITE_NAME}/{YEAR}')

# Save processed images using numpy
np.save('/content/drive/MyDrive/Capstone/data_raw/phenocamdata/processed_images.npy', processed_images)

"""## GCC, RCC"""

# Function to get the green mask at the beginning of the year
def get_begin_mask(image_path):
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(img_hsv, (11, 16, 39), (114, 134, 104))
    return mask

# Function to get the green mask at mid-year
def get_mid_mask(image_path):
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(img_hsv, (21, 10, 0), (110, 255, 173))
    return mask

# Function to get the situated area mask --ROI
def get_situated_area(begin_mask, mid_mask):
    situated_area = cv2.bitwise_xor(begin_mask, mid_mask)
    return situated_area

# Function to calculate GCC and RCC for the situated area
def calculate_gcc_rcc(image_path, situated_area):
    cur_img = cv2.imread(image_path)
    cur_img_rgb = cv2.cvtColor(cur_img, cv2.COLOR_BGR2RGB)
    cur_img_after_mask = cv2.bitwise_and(cur_img_rgb, cur_img_rgb, mask=situated_area)
    red = np.sum(cur_img_after_mask[:,:,0])
    green = np.sum(cur_img_after_mask[:,:,1])
    blue = np.sum(cur_img_after_mask[:,:,2])
    gcc = green / (green + red + blue)
    rcc = red / (red + green + blue)
    return gcc, rcc

# Usage for 2017 data
begin_img = img_files[0]  # Set the image you want at the beginning
mid_img = img_files[len(img_files) // 2]  # Set the image you want at mid-year

# Get masks
begin_mask = get_begin_mask(begin_img)
mid_mask = get_mid_mask(mid_img)
situated_area = get_situated_area(begin_mask, mid_mask)

# Calculate GCC and RCC over time for the situated area
gcc_over_time = []
rcc_over_time = []

for image_name in img_files:
    gcc_value, rcc_value = calculate_gcc_rcc(image_name, situated_area)
    gcc_over_time.append(gcc_value)
    rcc_over_time.append(rcc_value)

print(gcc_over_time[55])
print(rcc_over_time[0])

# Convert the list to a NumPy array
gcc_array = np.array(gcc_over_time)
rcc_array = np.array(rcc_over_time)
# Calculate the average
average_gcc = np.mean(gcc_array)
average_rcc = np.mean(rcc_array)
print(f"The average GCC over time is: {average_gcc}")
print(f"The average RCC over time is: {average_rcc}")

plt.title("GCC OVER TIME")
plt.xlabel("day")
plt.ylabel("gcc value")
plt.plot(np.arange(1,len(img_files)+1), gcc_over_time, color="green")
plt.show()

plt.title("RCC OVER TIME")
plt.xlabel("day")
plt.ylabel("rcc value")
plt.plot(np.arange(1,len(img_files)+1), rcc_over_time, color="red")
plt.show()

from datetime import datetime
# Function to extract date from image file name
def extract_date_from_filename(filename):
    # Assuming the file name contains the date information, extract it
    date_str = filename.split('_')[-4:-1]  # Extracting the date part
    date_str = '_'.join(date_str)
    image_date = datetime.strptime(date_str, "%Y_%m_%d")
    return image_date

# Function to label leaf growing dates based on SOS and EOS
def label_leaf_growth_dates(img_files, gcc_over_time, average_gcc):
    image_data = pd.DataFrame({
        'ImageID': range(1, len(img_files) + 1),
        'Filename': img_files,
        'Date': [extract_date_from_filename(file) for file in img_files],
        'GCC': gcc_over_time  # Replace with your actual GCC values
    })

    # Set SOS and EOS thresholds based on average GCC
    sos_threshold = 0.8 * average_gcc  # Adjust as needed
    eos_threshold = 1.1 * average_gcc  # Adjust as needed

    print(f"SOS Threshold: {sos_threshold}, EOS Threshold: {eos_threshold}")

    # Initialize labels column
    image_data['Label'] = 'Dormancy'  # Default label for dormancy stage

    # Handle missing values by linear interpolation
    image_data['GCC'] = image_data['GCC'].interpolate()

    # Print GCC statistics for debugging
    print(image_data['GCC'].describe())

    # Find SOS and EOS dates based on GCC curve
    sos_date = image_data.loc[image_data['GCC'] >= sos_threshold, 'Date'].min()
    eos_date = image_data.loc[image_data['GCC'] >= eos_threshold, 'Date'].min()

    print(f"SOS Date: {sos_date}, EOS Date: {eos_date}")

    # Update labels for images between SOS and EOS
    image_data.loc[(image_data['Date'] >= sos_date) & (image_data['Date'] <= eos_date), 'Label'] = 'Leaf Growth'
    image_data['DaysSinceSOS'] = (image_data['Date'] - sos_date).dt.days + 1

    return image_data

import pandas as pd

# Function to label leaf growing dates based on SOS and EOS
def label_leaf_growth_dates(img_files, gcc_over_time, average_gcc):
    image_data = pd.DataFrame({
        'ImageID': range(1, len(img_files) + 1),
        'Filename': img_files,
        'Date': [extract_date_from_filename(file) for file in img_files],
        'GCC': gcc_over_time  # Replace with your actual GCC values
    })

    # Set SOS and EOS thresholds based on average GCC
    sos_threshold = 0.8 * average_gcc  # Adjust as needed
    eos_threshold = 1.1 * average_gcc  # Adjust as needed

    print(f"SOS Threshold: {sos_threshold}, EOS Threshold: {eos_threshold}")

    # Initialize labels column
    image_data['Label'] = 'Dormancy'  # Default label for dormancy stage

    # Handle missing values by linear interpolation
    image_data['GCC'] = image_data['GCC'].interpolate()

    # Print GCC statistics for debugging
    print(image_data['GCC'].describe())

    # Find SOS and EOS dates based on GCC curve for each year
    for year in image_data['Date'].dt.year.unique():
        year_data = image_data[image_data['Date'].dt.year == year]

        sos_date = year_data.loc[year_data['GCC'] >= sos_threshold, 'Date'].min()
        eos_date = year_data.loc[year_data['GCC'] >= eos_threshold, 'Date'].min()

        print(f"Year: {year}, SOS Date: {sos_date}, EOS Date: {eos_date}")

        # Update labels for images between SOS and EOS
        image_data.loc[(image_data['Date'] >= sos_date) & (image_data['Date'] <= eos_date), 'Label'] = 'Leaf Growth'
        image_data.loc[image_data['Date'].dt.year == year, 'DaysSinceSOS'] = (image_data['Date'] - sos_date).dt.days + 1
        #image_data.loc[image_data['Date'].dt.year == year, 'DaysSinceSOS'] = (image_data['Date'] - sos_date).dt.days.astype(int) + 1

    return image_data

print(len(img_files))
print(len(gcc_over_time))
print(len([extract_date_from_filename(file) for file in img_files]))

# Apply the labeling function
labeled_data = label_leaf_growth_dates(img_files, gcc_over_time, average_gcc)

# Print the labeled dataset
print(labeled_data[['ImageID', 'Filename', 'Date', 'GCC', 'Label']])

# Save the labeled dataset to a CSV file
labeled_data.to_csv('/content/drive/MyDrive/Capstone/data_out/labeled_data.csv', index=False)

labeled_data

labeled_data[labeled_data['Label'] == 'Dormancy'].count()

"""##Visualize"""

# Function to plot labeled data
def plot_labeled_data(labeled_data):
    # Set the seaborn style for better aesthetics
    sns.set(style="whitegrid")

    # Create subplots for each year
    years = labeled_data['Date'].dt.year.unique()
    num_years = len(years)

    fig, axes = plt.subplots(num_years, 1, figsize=(12, 4 * num_years), sharex=True)

    for i, year in enumerate(years):
        year_data = labeled_data[labeled_data['Date'].dt.year == year]

        # Plot all data points
        axes[i].scatter(year_data['DaysSinceSOS'], year_data['GCC'], c='gray', label='All Data')

        # Highlight periods of leaf growth
        leaf_growth_data = year_data[year_data['Label'] == 'Leaf Growth']
        axes[i].scatter(leaf_growth_data['DaysSinceSOS'], leaf_growth_data['GCC'], c='green', label='Leaf Growth')

        # Highlight periods of dormancy
        dormancy_data = year_data[year_data['Label'] == 'Dormancy']
        axes[i].scatter(dormancy_data['DaysSinceSOS'], dormancy_data['GCC'], c='red', label='Dormancy')

        # Plot SOS and EOS dates
        axes[i].axvline(leaf_growth_data['DaysSinceSOS'].min(), color='blue', linestyle='--', label='SOS')
        axes[i].axvline(leaf_growth_data['DaysSinceSOS'].max(), color='orange', linestyle='--', label='EOS')

        axes[i].set_title(f'Leaf Growth and Dormancy Visualization - Year {year}')
        axes[i].set_ylabel('GCC')
        axes[i].legend()

    plt.xlabel('Days Since SOS')
    plt.tight_layout()
    plt.show()

# Plot the labeled data
plot_labeled_data(labeled_data)

"""## Model Building- Temp"""

!pip install tensorflow

!pip install --upgrade numpy scikit-learn

import os
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.applications import ResNet101
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

"""ResNet50 Model"""

def load_resnet50_model():
    base_model = ResNet50(weights='imagenet', include_top=False)
    #num_classes = 2
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(1, activation='sigmoid')(x)
    #predictions = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=base_model.input, outputs=predictions)

    for layer in base_model.layers:
        layer.trainable = False

    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

    return model

"""ResNet101 Model"""

def load_resnet101_model():
    base_model = ResNet101(weights='imagenet', include_top=False)

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(1, activation='sigmoid')(x)


    model = Model(inputs=base_model.input, outputs=predictions)

    for layer in base_model.layers:
        layer.trainable = False

    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

    return model

"""##Prepare Images and Train Model"""

def prepare_image_data(image_path_prefix, filenames, labels):
    X = []
    y = []

    for filename, label in zip(filenames, labels):
        img_path = os.path.join(image_path_prefix, filename)
        img = image.load_img(img_path, target_size=(224, 224))
        img_array = image.img_to_array(img)
        img_array = preprocess_input(img_array)
        X.append(img_array)
        y.append(1 if label == 'Leaf Growth' else 0)

    return np.array(X), np.array(y)

def train_resnet50_model(model, X_train, y_train, X_val, y_val, epochs=5, batch_size=32):
    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))
    return history

def train_resnet101_model(model, X_train, y_train, X_val, y_val, epochs=5, batch_size=32):
    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))
    return history

"""##Model Evaluation"""

def evaluate_model(model, X_test, y_test):
    loss, accuracy = model.evaluate(X_test, y_test)
    print(f"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}")

def predict_image_phase(model, image_path):
    img = image.load_img(image_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    prediction = model.predict(img_array)

    if prediction >= 0.5:
        return 'Leaf Growth'
    else:
        return 'Dormancy'

"""Train, Test, Validation"""

# labeled_data contains the labeled dataset with 'Filename', 'Label', and 'DaysSinceSOS' columns
image_path_prefix = '/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/'

# Split data into training, validation, and testing sets
X_train, X_temp, y_train, y_temp = train_test_split(labeled_data['Filename'], labeled_data['Label'], test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Load and prepare image data
X_train, y_train = prepare_image_data(image_path_prefix, X_train, y_train)
X_val, y_val = prepare_image_data(image_path_prefix, X_val, y_val)
X_test, y_test = prepare_image_data(image_path_prefix, X_test, y_test)

# Load ResNet50 model
resnet50_model = load_resnet50_model()

# Train the model
history = train_resnet50_model(resnet50_model, X_train, y_train, X_val, y_val, epochs=5, batch_size=32)

# Evaluate the model
evaluate_model(resnet50_model, X_test, y_test)

# Load ResNet50 model
resnet101_model = load_resnet101_model()

# Train the model
history_1 = train_resnet101_model(resnet101_model, X_train, y_train, X_val, y_val, epochs=5, batch_size=32)

# Evaluate the model
evaluate_model(resnet101_model, X_test, y_test)

"""## Test Model"""

# Test the prediction function with a sample image
sample_image_path = '/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/2017/01/NEON.D01.HARV.DP1.00033_2017_01_01_120006.jpg'
predicted_phase = predict_image_phase(resnet50_model, sample_image_path)
print(f"Predicted Phase: {predicted_phase}")

# Test the prediction function with a sample image
sample_image_path = '/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/2017/12/NEON.D01.HARV.DP1.00033_2017_12_28_120006.jpg'
predicted_phase = predict_image_phase(resnet50_model, sample_image_path)
print(f"Predicted Phase: {predicted_phase}")

sample_image_path = '/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/2019/02/NEON.D01.HARV.DP1.00033_2019_02_18_120005.jpg'
#sample_image_path = '/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/2019/05/NEON.D01.HARV.DP1.00033_2019_05_31_120006.jpg'
#sample_image_path = '/content/drive/MyDrive/Capstone/data_raw/phenocamdata/NEON.D01.HARV.DP1.00033/2019/11/NEON.D01.HARV.DP1.00033_2019_11_14_120005.jpg'
predicted_phase = predict_image_phase(resnet50_model, sample_image_path)
print(f"Predicted Phase: {predicted_phase}")